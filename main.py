# main.py
import os
import asyncio
from fastapi import FastAPI, Request
from openai import OpenAI

# ------------- –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI -------------
api_key = os.getenv("OPENAI_API_KEY")
print("ENV OPENAI_API_KEY exists:", bool(api_key), flush=True)
client = OpenAI(api_key=api_key)

app = FastAPI()


# ------------- health & debug -------------
@app.get("/")
async def health():
    return {"ok": True}

@app.get("/debug-openai")
async def debug_openai():
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å OpenAI (–±–µ–∑ –ê–ª–∏—Å—ã)."""
    try:
        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π –±–æ—Ç."},
                {"role": "user", "content": "–°–∫–∞–∂–∏ —Å–ª–æ–≤–æ –ü–ò–ù–ì."},
            ],
            temperature=0.0,
        )
        txt = r.choices[0].message.content.strip()
        return {"ok": True, "reply": txt}
    except Exception as e:
        return {"ok": False, "error": repr(e)}


# ------------- —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ GPT -------------
def ask_gpt_sync(prompt: str) -> str:
    system = "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ö–∞–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
    r = client.chat.completions.create(
        model="gpt-4o-mini",  # –±—ã—Å—Ç—Ä—ã–π –∏ –¥–µ—à—ë–≤—ã–π
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": prompt},
        ],
        temperature=0.7,
    )
    return r.choices[0].message.content.strip()


# ------------- –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ê–ª–∏—Å—ã -------------
@app.post("/alice")
async def alice_handle(request: Request):
    body = await request.json()
    print("ALICE BODY:", body, flush=True)

    req = (body.get("request") or {})
    user_text = (req.get("original_utterance") or req.get("command") or "").strip()

    # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî —Å–æ–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ nlu.tokens
    if not user_text:
        nlu = (req.get("nlu") or {})
        tokens = nlu.get("tokens") or []
        if tokens:
            user_text = " ".join(tokens).strip()

    print("USER_TEXT:", repr(user_text), flush=True)

    # –≤—ã—Ö–æ–¥
    if user_text.lower() in {"–≤—ã—Ö–æ–¥", "—Å—Ç–æ–ø", "—Ö–≤–∞—Ç–∏—Ç"}:
        reply = "–î–æ —Å–≤—è–∑–∏! –ó–æ–≤–∏, –µ—Å–ª–∏ —á—Ç–æ."
        return {
            "version": body.get("version", "1.0"),
            "response": {"text": reply, "tts": reply, "end_session": True},
        }

    # –ø—É—Å—Ç–æ ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if not user_text:
        reply = "–ü—Ä–∏–≤–µ—Ç! –Ø –ö–∞–π. –°–ø—Ä–æ—Å–∏ –º–µ–Ω—è –æ —á—ë–º —É–≥–æ–¥–Ω–æ."
        return {
            "version": body.get("version", "1.0"),
            "response": {"text": reply, "tts": reply, "end_session": False},
        }

    # –≤—ã–∑–æ–≤ GPT —Å –ø–æ–Ω—è—Ç–Ω—ã–º –ª–æ–≥–æ–º
    try:
        # –Ø–Ω–¥–µ–∫—Å –¥–∞—ë—Ç ~3‚Äì3.5 —Å. –°—Ç–∞–≤–∏–º 3.0 ‚Äî –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        reply = await asyncio.wait_for(
            asyncio.to_thread(ask_gpt_sync, user_text),
            timeout=3.0
        )
    except asyncio.TimeoutError:
        print("OPENAI TIMEOUT", flush=True)
        reply = "–ü–æ–¥—É–º–∞–ª... –¥–∞–≤–∞–π –ø—Ä–æ–¥–æ–ª–∂–∏–º, —è –ø–æ–¥–∫–ª—é—á—É—Å—å üòâ"
    except Exception as e:
        print("OPENAI ERROR:", repr(e), flush=True)
        reply = f"–ü–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –º–æ–¥–µ–ª–∏. –¢—ã –Ω–∞–ø–∏—Å–∞–ª: ¬´{user_text}¬ª."

    return {
        "version": body.get("version", "1.0"),
        "response": {"text": reply, "tts": reply, "end_session": False},
    }
