# main.py
import os
import asyncio
from fastapi import FastAPI, Request
from openai import OpenAI

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
api_key = os.getenv("OPENAI_API_KEY")
print("ENV OPENAI_API_KEY exists:", bool(api_key), flush=True)
client = OpenAI(api_key=api_key)

app = FastAPI()

# ---- health ----
@app.get("/")
async def health():
    return {"ok": True}

# ---- –±—ã—Å—Ç—Ä—ã–π —Å–∞–º–æ—Ç–µ—Å—Ç –±–µ–∑ –ê–ª–∏—Å—ã ----
@app.get("/debug-openai")
async def debug_openai():
    try:
        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π –±–æ—Ç."},
                {"role": "user", "content": "–°–∫–∞–∂–∏ —Å–ª–æ–≤–æ –ü–ò–ù–ì."},
            ],
            temperature=0.0,
            max_tokens=16,
        )
        return {"ok": True, "reply": r.choices[0].message.content.strip()}
    except Exception as e:
        return {"ok": False, "error": repr(e)}

# ---- —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ GPT ----
def ask_gpt_sync(prompt: str) -> str:
    system = "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ö–∞–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": prompt},
        ],
        temperature=0.7,
        max_tokens=64,   # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç –ø—Ä–∏—Ö–æ–¥–∏–ª –±—ã—Å—Ç—Ä–µ–µ
    )
    return r.choices[0].message.content.strip()

# ---- –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ê–ª–∏—Å—ã ----
@app.post("/alice")
async def alice_handle(request: Request):
    body = await request.json()
    print("ALICE BODY:", body, flush=True)

    req = (body.get("request") or {})
    user_text = (req.get("original_utterance") or req.get("command") or "").strip()
    if not user_text:
        nlu = (req.get("nlu") or {})
        tokens = nlu.get("tokens") or []
        if tokens:
            user_text = " ".join(tokens).strip()

    print("USER_TEXT:", repr(user_text), flush=True)

    # –≤—ã—Ö–æ–¥ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    if user_text.lower() in {"–≤—ã—Ö–æ–¥", "—Å—Ç–æ–ø", "—Ö–≤–∞—Ç–∏—Ç"}:
        reply = "–î–æ —Å–≤—è–∑–∏! –ó–æ–≤–∏, –µ—Å–ª–∏ —á—Ç–æ."
        return {
            "version": body.get("version", "1.0"),
            "response": {"text": reply, "tts": reply, "end_session": True},
        }

    # –ø—É—Å—Ç–æ ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if not user_text:
        reply = "–ü—Ä–∏–≤–µ—Ç! –Ø –ö–∞–π. –°–ø—Ä–æ—Å–∏ –º–µ–Ω—è –æ —á—ë–º —É–≥–æ–¥–Ω–æ."
        return {
            "version": body.get("version", "1.0"),
            "response": {"text": reply, "tts": reply, "end_session": False},
        }

    # –≤—ã–∑–æ–≤ GPT —Å —Ç–∞–π–º–∞—É—Ç–æ–º ~3.5—Å
    try:
        reply = await asyncio.wait_for(
            asyncio.to_thread(ask_gpt_sync, user_text),
            timeout=3.5
        )
    except asyncio.TimeoutError:
        print("OPENAI TIMEOUT", flush=True)
        reply = "–ü–æ–¥—É–º–∞–ª... –¥–∞–≤–∞–π –ø—Ä–æ–¥–æ–ª–∂–∏–º, —è –ø–æ–¥–∫–ª—é—á—É—Å—å üòâ"
    except Exception as e:
        print("OPENAI ERROR:", repr(e), flush=True)
        reply = f"–ü–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –º–æ–¥–µ–ª–∏. –¢—ã –Ω–∞–ø–∏—Å–∞–ª: ¬´{user_text}¬ª."

    return {
        "version": body.get("version", "1.0"),
        "response": {"text": reply, "tts": reply, "end_session": False},
    }
